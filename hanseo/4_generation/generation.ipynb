{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 가상의 기사 제목 데이터 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 제목 생성을 시작합니다.\n",
      "generated_raw.csv 기존 파일을 삭제하고 새로 생성합니다.\n",
      "배치 1/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 2/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 3/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 4/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 5/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 6/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 7/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 19개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 8/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 9/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 10/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 17개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 11/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 12/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 13/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 17개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 14/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 19개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 15/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 16/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 17/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 9개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 18/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 19/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 4개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 20/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 10개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 21/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 22/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 23/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 14개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 24/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 10개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 25/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 13개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 26/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 6개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 27/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 13개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 28/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 29/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 10개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 30/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 17개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 31/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 11개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 32/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 7개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 33/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 13개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 34/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 10개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 35/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 5개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 36/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 10개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 37/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 38/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 18개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 39/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 13개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 40/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 7개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 41/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 5개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 42/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 17개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 43/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 12개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 44/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 3개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 45/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 20개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 46/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 11개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 47/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 10개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 48/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 2개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 49/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 10개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "배치 50/50: 20개의 뉴스 제목 생성 중...\n",
      "생성된 뉴스 제목 1개가 'generated_raw.csv' 파일에 저장되었습니다.\n",
      "모든 뉴스 제목 생성이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gemini 1.5 flash LLM을 이용하여, 가상의 기사 제목 데이터와 타겟을 생성하는 코드입니다.\n",
    "\"\"\"\n",
    "\n",
    "OUTPUT_FILE = \"generated_raw.csv\"\n",
    "GEMINI_API_KEY = \"AIzaSyCi7mh8iSC5JTycmqb39ypK0sLtPJkJ7R4\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "TOTAL_TITLES = 1000  # 총 생성할 뉴스 기사 제목 수\n",
    "NUM_TITLES = 20     # 한 번에 생성할 뉴스 기사 제목 수\n",
    "MAX_RETRIES = 3     # 최대 재시도 횟수\n",
    "F1_THRESHOLD = 0.3  # 중복 판단을 위한 F1 Score 임계값\n",
    "\n",
    "# API 키 설정\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GEMINI_API_KEY\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\")\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"num_titles\"],\n",
    "    template=f\"\"\"\n",
    "- 다음 요구사항에 맞게 \"{\"{num_titles}\"}개의 가상의 뉴스 기사 제목과 레이블을 생성하세요.\n",
    "\n",
    "- **제목 생성 지침**:\n",
    "  - 일반적인 뉴스 기사에서 사용되는 표현과 어휘를 사용하세요.\n",
    "  - 각 제목은 간결하고, 명확하며, 문법적으로 정확해야 합니다.\n",
    "  - 뉴스 기사 제목의 주제는 다양해야 합니다. 특정 주제에 편향되지 말고, 여러 분야를 고루 포함해주세요.\n",
    "  - 구체적인 인물, 지역, 단체 이름을 사용하되, 다양한 이름을 사용해주세요.\n",
    "\n",
    "- **레이블 생성 지침**:\n",
    "  - 각 제목에 적합한 정수 레이블(0부터 6까지)을 할당하세요.\n",
    "  - 레이블은 생성한 제목의 주제에 알맞게 분류되어야 합니다.\n",
    "\n",
    "- **출력 형식**:\n",
    "  - 제목과 레이블은 쉼표로 구분하여 아래와 같은 형식으로 출력해주세요:\n",
    "    1. 첫 번째 제목,레이블\n",
    "    2. 두 번째 제목,레이블\n",
    "    3. 세 번째 제목,레이블\n",
    "    ...\n",
    "\n",
    "- **예시 데이터**:\n",
    "    서울에 다시 오존주의보…도심·서북·동북권 발령종합,0\n",
    "    충북 가마솥더위 지속…주말도 더워요,0\n",
    "    춘천 MBC 나이야가라 한국방송대상 작품상 수상,0\n",
    "    코리아둘레길 남해안길 남파랑길로 불러주세요,0\n",
    "\n",
    "    대한항공 우리카드 꺾고 3연승…GS칼텍스 1라운드 전승종합,1\n",
    "    프로농구 SK 삼성 꺾고 하루 만에 공동 3위,1\n",
    "    포틀랜드 워싱턴 꺾고 NBA 서부콘퍼런스 선두 도약,1\n",
    "    SK로 이적한 강승호 LG서 좋은 모습 못 보여드려 죄송,1\n",
    "\n",
    "    지소미아 종료까지 8일…美 압박 속 고민 깊어지는 文대통령,2\n",
    "    큰절하는 새누리당 당직자들,2\n",
    "    민주 5·18 모독 한국당 압박 지속…헌정질서 파괴 옹호,2\n",
    "    홍준표 황교안 선거권 없어…전대출마 자격 운운 난센스,2\n",
    "\n",
    "    광주교육청 9급 지방공무원 73명 공개 채용,3\n",
    "    춘천시 환경사업소 관련 기자회견,3\n",
    "    차의과학대 현대그린푸드·현대백화점과 사회공헌협약 체결,3\n",
    "    등교하며 손 소독·발열 검사 필수,3\n",
    "\n",
    "    한국형 발사체 75t 엔진 첫 연소시험 성공,4\n",
    "    삼성·애플·LG·구글 스마트폰 가을대전 임박,4\n",
    "    아이폰11 프로 써보니…프로다운 카메라 성능 기대 이상,4\n",
    "    모바일 컴퓨팅 미래는…서울서 국제학회 ACM 모비시스 개막,4\n",
    "\n",
    "    美금융사 가상화폐 경계령…비자 CEO 거래처리 안할 것,5\n",
    "    코스닥 진입 수월해진다…자본잠식 등 상장요건 개편,5\n",
    "    KB증권 2분기 영업익 1천5억원…2.21% 증가,5\n",
    "    테슬라 4분기 연속 흑자…국내 2차전지 업체 수혜 기대,5\n",
    "\n",
    "    네덜란드 정부 보스니아 무슬림 학살사건에 10% 책임,6\n",
    "    유럽 최악 한파에 난민들 피해속출…폐렴·저체온증 극심,6\n",
    "    대선출마 앞둔 바이든의 나쁜손 또 폭로…코 비비려고 했다,6\n",
    "    김정은 베이징 경제기술개발구 제약회사 동인당 공장 방문속보,6\n",
    "\n",
    "\n",
    "- **주의사항**:\n",
    "  - 예시와 동일한 데이터를 절대로 출력하지 마세요.\n",
    "  - 생성된 제목은 독창적이어야 합니다.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    텍스트 전처리 함수: 소문자 변환, 구두점 제거, 공백 정리\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def compute_f1(title1, title2):\n",
    "    \"\"\"\n",
    "    두 텍스트 간의 F1 Score 계산 함수\n",
    "    \"\"\"\n",
    "    tokens1 = set(preprocess_text(title1).split())\n",
    "    tokens2 = set(preprocess_text(title2).split())\n",
    "    \n",
    "    if not tokens1 or not tokens2:\n",
    "        return 0.0\n",
    "    \n",
    "    common_tokens = tokens1.intersection(tokens2)\n",
    "    precision = len(common_tokens) / len(tokens1)\n",
    "    recall = len(common_tokens) / len(tokens2)\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return f1\n",
    "\n",
    "def generate_news_titles(num_titles, existing_titles):\n",
    "    titles = []\n",
    "    retries = 0\n",
    "    while len(titles) < num_titles and retries < MAX_RETRIES:\n",
    "        remaining = num_titles - len(titles)\n",
    "        current_prompt = prompt_template.format(num_titles=remaining)\n",
    "        try:\n",
    "            # 모델을 사용하여 텍스트 생성\n",
    "            response = model.invoke(current_prompt)\n",
    "            response_text = response.content.strip()\n",
    "\n",
    "            # 생성된 제목과 타겟을 리스트로 분리\n",
    "            for line in response_text.split('\\n'):\n",
    "                # 번호와 점, 타겟을 제거하여 실제 제목과 타겟 추출\n",
    "                match = re.match(r'^\\d+\\.\\s*(.+?),\\s*(\\d+)$', line)\n",
    "                if match:\n",
    "                    title = match.group(1).strip()\n",
    "                    target = match.group(2).strip()\n",
    "                    if not title or not target.isdigit():\n",
    "                        continue\n",
    "                    target = int(target)\n",
    "                    # 중복 검사\n",
    "                    is_duplicate = False\n",
    "                    for existing_title in existing_titles + titles:\n",
    "                        f1 = compute_f1(title, existing_title['text'])\n",
    "                        if f1 >= F1_THRESHOLD:\n",
    "                            is_duplicate = True\n",
    "                            break\n",
    "                    if not is_duplicate:\n",
    "                        titles.append({\"text\": title, \"target\": target})\n",
    "                        if len(titles) == num_titles:\n",
    "                            break\n",
    "                else:\n",
    "                    # 예기치 않은 형식의 응답 처리\n",
    "                    continue\n",
    "\n",
    "            if len(titles) < num_titles:\n",
    "                retries += 1\n",
    "                time.sleep(2)  # 잠시 대기 후 재시도\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            time.sleep(5)  # 잠시 대기 후 재시도\n",
    "\n",
    "    return titles\n",
    "\n",
    "def save_to_csv(titles, output_file, start_index):\n",
    "    data = []\n",
    "    for i, item in enumerate(titles):\n",
    "        data.append({\n",
    "            \"ID\": f\"gemini-{start_index + i:05d}\",\n",
    "            \"text\": item[\"text\"],\n",
    "            \"target\": item[\"target\"]\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # 파일이 이미 존재하면 헤더 없이 추가, 아니면 헤더와 함께 생성\n",
    "    if os.path.exists(output_file):\n",
    "        df.to_csv(output_file, mode='a', index=False, header=False, encoding='utf-8-sig')\n",
    "    else:\n",
    "        df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"생성된 뉴스 제목 {len(data)}개가 '{output_file}' 파일에 저장되었습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"뉴스 제목 생성을 시작합니다.\")\n",
    "    \n",
    "    # 기존 OUTPUT_FILE이 존재하면 삭제\n",
    "    if os.path.exists(OUTPUT_FILE):\n",
    "        os.remove(OUTPUT_FILE)\n",
    "        print(f\"{OUTPUT_FILE} 기존 파일을 삭제하고 새로 생성합니다.\")\n",
    "    \n",
    "    existing_titles = []  # 기존 제목 목록 초기화\n",
    "    total_generated = 0  # 총 생성된 제목 수 초기화\n",
    "    \n",
    "    total_batches = (TOTAL_TITLES + NUM_TITLES - 1) // NUM_TITLES  # 총 배치 수 계산\n",
    "    \n",
    "    for batch_num in range(total_batches):\n",
    "        remaining_titles = TOTAL_TITLES - total_generated\n",
    "        current_batch_size = NUM_TITLES if remaining_titles >= NUM_TITLES else remaining_titles\n",
    "        \n",
    "        print(f\"배치 {batch_num + 1}/{total_batches}: {current_batch_size}개의 뉴스 제목 생성 중...\")\n",
    "        \n",
    "        new_titles = generate_news_titles(current_batch_size, existing_titles)\n",
    "        \n",
    "        if new_titles:\n",
    "            start_index = total_generated\n",
    "            save_to_csv(new_titles, OUTPUT_FILE, start_index)\n",
    "            existing_titles.extend(new_titles)\n",
    "            total_generated += len(new_titles)\n",
    "        else:\n",
    "            print(f\"배치 {batch_num + 1}에서 뉴스 제목 생성에 실패했습니다.\")\n",
    "        \n",
    "        time.sleep(1)  # 각 배치 사이에 잠시 대기\n",
    "    \n",
    "    print(\"모든 뉴스 제목 생성이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 후처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "후처리가 완료되었습니다. 결과는 generated.csv에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "위에서 생성한 generated_raw.csv를 후처리하는 코드입니다.\n",
    "후처리 결과는 generated.csv로 저장됩니다.\n",
    "\"\"\"\n",
    "\n",
    "INPUT_FILE = \"generated_raw.csv\"\n",
    "OUTPUT_FILE = \"generated.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# 1. 특수 문자 처리\n",
    "df['text'] = (\n",
    "    df['text']\n",
    "    .str.replace('\"', '', regex=False)\n",
    "    .str.replace(\"'\", '', regex=False)\n",
    "    .str.replace('#', '', regex=False)\n",
    "    .str.replace('*', '', regex=False)\n",
    "    .str.replace(', ', ' ', regex=False)\n",
    "    .str.replace('-', ' ', regex=False)\n",
    "    .str.replace('...', '…', regex=False)\n",
    "    .str.replace('….', '…', regex=False)\n",
    "    .str.replace(' · ', '·', regex=False)\n",
    "    .str.replace('· ', '·', regex=False)\n",
    "    .str.replace(' ·', '·', regex=False)\n",
    "    .str.replace('  ', ' ', regex=False)\n",
    "    .str.replace('  ', ' ', regex=False)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# 2. 후처리 결과 저장\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"후처리가 완료되었습니다. 결과는 {OUTPUT_FILE}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 잘 labeling 됐는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "generaion을 통해 생성된 generated.csv가\n",
    "잘 labeling 됐는지 '육안으로 확인하기 위한'\n",
    "generated_analysis.csv 파일을 생성하는 코드입니다.\n",
    "\"\"\"\n",
    "INPUT_FILE = 'generated.csv'\n",
    "OUTPUT_FILE = 'generated_analysis.csv'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# target 값 매핑 딕셔너리\n",
    "target_mapping = {\n",
    "    0: '생활문화',\n",
    "    1: '스포츠',\n",
    "    2: '정치',\n",
    "    3: '사회',\n",
    "    4: 'IT 과학',\n",
    "    5: '경제',\n",
    "    6: '세계'\n",
    "}\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# target을 기준으로 오름차순 정렬\n",
    "df = df.sort_values(by='target')\n",
    "\n",
    "# target 값 매핑\n",
    "df['target'] = df['target'].map(target_mapping)\n",
    "\n",
    "# 저장\n",
    "df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig')\n",
    "print(f\"새로운 CSV 파일이 '{OUTPUT_FILE}'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 생성한 가상의 기사 제목 데이터를 back-translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### back-translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.에서 생성한 generated.csv를\n",
    "DeepL API를 이용해 일본어로 back-translation 하는 코드입니다.\n",
    "\"\"\"\n",
    "\n",
    "INPUT_FILE = \"generated.csv\"\n",
    "OUTPUT_FILE = \"generated_JP_raw.csv\"\n",
    "DEEPL_API_URL = \"https://api-free.deepl.com/v2/translate\"\n",
    "DEEPL_API_KEY = \"40122ee2-c4c5-419b-881c-c854abcf8df5:fx\"\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "\n",
    "REPEAT = 1  # 각 데이터에 대해 역번역을 수행하는 횟수\n",
    "SAVE_INTERVAL = 10  # 중간 저장할 데이터 개수\n",
    "\n",
    "def back_translate(text):\n",
    "    params_ko_ja = {\n",
    "        'auth_key': DEEPL_API_KEY,\n",
    "        'text': text,\n",
    "        'source_lang': 'KO',\n",
    "        'target_lang': 'JA',\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(DEEPL_API_URL, data=params_ko_ja)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        japanese_text = result['translations'][0]['text']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"번역 오류 (한국어 -> 일본어): {e}\")\n",
    "        return text  # 오류 발생 시 원본 텍스트 반환\n",
    "\n",
    "    # 일본어 -> 한국어 번역\n",
    "    params_ja_ko = {\n",
    "        'auth_key': DEEPL_API_KEY,\n",
    "        'text': japanese_text,\n",
    "        'source_lang': 'JA',\n",
    "        'target_lang': 'KO',\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(DEEPL_API_URL, data=params_ja_ko)\n",
    "        response.raise_for_status()\n",
    "        result = response.json()\n",
    "        korean_text = result['translations'][0]['text']\n",
    "        return korean_text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"번역 오류 (일본어 -> 한국어): {e}\")\n",
    "        return text  # 오류 발생 시 원본 텍스트 반환\n",
    "\n",
    "# 데이터 불러오기\n",
    "data = pd.read_csv(INPUT_FILE)\n",
    "data = data[['ID', 'text', 'target']]\n",
    "total_characters = data['text'].str.len().sum()\n",
    "\n",
    "print(f\"원본 데이터 개수: {len(data)}\")\n",
    "print(f\"총 글자 수: {total_characters}\")\n",
    "\n",
    "texts_to_translate = data['text'].tolist()\n",
    "REQUEST_DELAY = 1  # API 요청 사이에 지연 추가 (단위: 초)\n",
    "\n",
    "print(\"back-translation을 시작합니다...\")\n",
    "\n",
    "# 기존 출력 파일이 있으면 덮어쓰기\n",
    "if os.path.exists(OUTPUT_FILE):\n",
    "    os.remove(OUTPUT_FILE)\n",
    "\n",
    "for r in range(REPEAT):\n",
    "    print(f\"{r + 1}번째 증강을 시작합니다...\")\n",
    "    translated_texts = []\n",
    "    batch = []  # 중간 저장을 위한 배치 리스트\n",
    "\n",
    "    for idx, text in enumerate(texts_to_translate):\n",
    "        translated = back_translate(text)\n",
    "        translated_texts.append(translated)\n",
    "        batch.append({\n",
    "            'ID': data.at[idx, 'ID'],\n",
    "            'text': translated,\n",
    "            'target': data.at[idx, 'target']\n",
    "        })\n",
    "        print(f\"번역 완료: {idx + 1}/{len(texts_to_translate)}\")\n",
    "        time.sleep(REQUEST_DELAY)  # API 요청 사이에 지연 추가\n",
    "\n",
    "        # SAVE_INTERVAL마다 중간 저장\n",
    "        if (idx + 1) % SAVE_INTERVAL == 0:\n",
    "            batch_df = pd.DataFrame(batch)\n",
    "            if not os.path.exists(OUTPUT_FILE):\n",
    "                # 첫 저장 시 헤더 포함\n",
    "                batch_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig', mode='w')\n",
    "            else:\n",
    "                # 이후 저장 시 헤더 제외\n",
    "                batch_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig', mode='a', header=False)\n",
    "            print(f\"{idx + 1}개 데이터가 '{OUTPUT_FILE}'에 저장되었습니다.\")\n",
    "            batch = []  # 배치 초기화\n",
    "\n",
    "    # 마지막에 남은 데이터 저장\n",
    "    if batch:\n",
    "        batch_df = pd.DataFrame(batch)\n",
    "        if not os.path.exists(OUTPUT_FILE):\n",
    "            batch_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig', mode='w')\n",
    "        else:\n",
    "            batch_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8-sig', mode='a', header=False)\n",
    "        print(f\"남은 {len(batch)}개 데이터가 '{OUTPUT_FILE}'에 저장되었습니다.\")\n",
    "\n",
    "print(f\"'{OUTPUT_FILE}'로 저장이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 후처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "위에서 생성한 generated_JP_raw.csv를 후처리하는 코드입니다.\n",
    "후처리 결과는 generated_JP.csv로 저장됩니다.\n",
    "\"\"\"\n",
    "\n",
    "INPUT_FILE = \"generated_JP_raw.csv\"\n",
    "OUTPUT_FILE = \"generated_JP.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "# 1. 특수 문자 처리\n",
    "df['text'] = (\n",
    "    df['text']\n",
    "    .str.replace('\"', '', regex=False)\n",
    "    .str.replace(\"'\", '', regex=False)\n",
    "    .str.replace('#', '', regex=False)\n",
    "    .str.replace('*', '', regex=False)\n",
    "    .str.replace(', ', ' ', regex=False)\n",
    "    .str.replace('-', ' ', regex=False)\n",
    "    .str.replace('...', '…', regex=False)\n",
    "    .str.replace('….', '…', regex=False)\n",
    "    .str.replace(' · ', '·', regex=False)\n",
    "    .str.replace('· ', '·', regex=False)\n",
    "    .str.replace(' ·', '·', regex=False)\n",
    "    .str.replace('  ', ' ', regex=False)\n",
    "    .str.replace('  ', ' ', regex=False)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# 2. 후처리 결과 저장\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"후처리가 완료되었습니다. 결과는 {OUTPUT_FILE}에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
